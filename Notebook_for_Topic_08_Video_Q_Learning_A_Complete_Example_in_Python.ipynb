{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ybe8CY07zp7D"
   },
   "source": [
    "## Scenario - Robots in a Warehouse\n",
    "A growing e-commerce company is building a new warehouse, and the company would like all of the picking operations in the new warehouse to be performed by warehouse robots.\n",
    "* In the context of e-commerce warehousing, “picking” is the task of gathering individual items from various locations in the warehouse in order to fulfill customer orders.\n",
    "\n",
    "After picking items from the shelves, the robots must bring the items to a specific location within the warehouse where the items can be packaged for shipping.\n",
    "\n",
    "In order to ensure maximum efficiency and productivity, the robots will need to learn the shortest path between the item packaging area and all other locations within the warehouse where the robots are allowed to travel.\n",
    "* We will use Q-learning to accomplish this task!\n",
    "\n",
    "#### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rfdhGGMsw1H7"
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kq-QPfDnx4Fo"
   },
   "source": [
    "## Define the Environment\n",
    "The environment consists of **states**, **actions**, and **rewards**. States and actions are inputs for the Q-learning AI agent, while the possible actions are the AI agent's outputs.\n",
    "#### States\n",
    "The states in the environment are all of the possible locations within the warehouse. Some of these locations are for storing items (**black squares**), while other locations are aisles that the robot can use to travel throughout the warehouse (**white squares**). The **green square** indicates the item packaging and shipping area.\n",
    "\n",
    "The black and green squares are **terminal states**!\n",
    "\n",
    "![warehouse map](https://www.danielsoper.com/teaching/img/08-warehouse-map.png)\n",
    "\n",
    "The AI agent's goal is to learn the shortest path between the item packaging area and all of the other locations in the warehouse where the robot is allowed to travel.\n",
    "\n",
    "As shown in the image above, there are 121 possible states (locations) within the warehouse. These states are arranged in a grid containing 11 rows and 11 columns. Each location can hence be identified by its row and column index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9AdpFVfy6ya9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]] (11, 11, 4)\n"
     ]
    }
   ],
   "source": [
    "#define the shape of the environment (i.e., its states)\n",
    "environment_rows = 11\n",
    "environment_columns = 11\n",
    "\n",
    "#Create a 3D numpy array to hold the current Q-values for each state and action pair: Q(s, a)\n",
    "#The array contains 11 rows and 11 columns (to match the shape of the environment), as well as a third \"action\" dimension.\n",
    "#The \"action\" dimension consists of 4 layers that will allow us to keep track of the Q-values for each possible action in\n",
    "#each state (see next cell for a description of possible actions).\n",
    "#The value of each (state, action) pair is initialized to 0.\n",
    "q_values = np.zeros((environment_rows, environment_columns, 4)) \n",
    "print(q_values,np.shape(q_values))\n",
    "#environment_rows determines which row (0-10) of the possible states(locations) of the warehouse\n",
    "#environment_columns determines which row (0-10) of the possible states(locations) of the warehouse\n",
    "#4 which of the four actions 0=Up/1=Right/2=Down/3=Left is taken\n",
    "#So e.g. q_values(2,3,2) => Q-value obtained of being in row 2, column 3 of the warehouse and taking \"Down\" action\n",
    "#test = np.zeros((2,3,4))\n",
    "#print(test)\n",
    "#np.shape(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07gGSNz07xtP"
   },
   "source": [
    "#### Actions\n",
    "The actions that are available to the AI agent are to move the robot in one of four directions:\n",
    "* Up\n",
    "* Right\n",
    "* Down\n",
    "* Left\n",
    "\n",
    "Obviously, the AI agent must learn to avoid driving into the item storage locations (e.g., shelves)!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "z43QX_t080q3"
   },
   "outputs": [],
   "source": [
    "#define actions\n",
    "#numeric action codes: 0 = up, 1 = right, 2 = down, 3 = left\n",
    "actions = ['up', 'right', 'down', 'left']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X25vn4VKw2as"
   },
   "source": [
    "#### Rewards\n",
    "The last component of the environment that we need to define are the **rewards**.\n",
    "\n",
    "To help the AI agent learn, each state (location) in the warehouse is assigned a reward value.\n",
    "\n",
    "The agent may begin at any white square, but its goal is always the same: ***to maximize its total rewards***!\n",
    "\n",
    "Negative rewards (i.e., **punishments**) are used for all states except the goal.\n",
    "* This encourages the AI to identify the *shortest path* to the goal by *minimizing its punishments*!\n",
    "\n",
    "![warehouse map](https://www.danielsoper.com/teaching/img/08-warehouse-map-rewards.png)\n",
    "\n",
    "To maximize its cumulative rewards (by minimizing its cumulative punishments), the AI agent will need find the shortest paths between the item packaging area (green square) and all of the other locations in the warehouse where the robot is allowed to travel (white squares). The agent will also need to learn to avoid crashing into any of the item storage locations (black squares)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GIJu7XsLXw62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100. -100. -100. -100. -100.  100. -100. -100. -100. -100. -100.]\n",
      "[-100.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1. -100.]\n",
      "[-100.   -1. -100. -100. -100. -100. -100.   -1. -100.   -1. -100.]\n",
      "[-100.   -1.   -1.   -1.   -1.   -1.   -1.   -1. -100.   -1. -100.]\n",
      "[-100. -100. -100.   -1. -100. -100. -100.   -1. -100. -100. -100.]\n",
      "[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      "[-100. -100. -100. -100. -100.   -1. -100. -100. -100. -100. -100.]\n",
      "[-100.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1. -100.]\n",
      "[-100. -100. -100.   -1. -100. -100. -100.   -1. -100. -100. -100.]\n",
      "[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      "[-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.]\n"
     ]
    }
   ],
   "source": [
    "#Create a 2D numpy array to hold the rewards for each state.\n",
    "#The array contains 11 rows and 11 columns (to match the shape of the environment), and each value is initialized to -100.\n",
    "rewards = np.full((environment_rows, environment_columns), -100.) #np.full(shape,fill value)\n",
    "rewards[0, 5] = 100. #set the reward for the packaging area (i.e., the goal) to 100\n",
    "\n",
    "#define aisle locations (i.e., white squares) for rows 1 through 9\n",
    "aisles = {} #store locations in a dictionary\n",
    "aisles[1] = [i for i in range(1, 10)] #Row 1, Columns white : 1-9\n",
    "aisles[2] = [1, 7, 9] #Row 2, Columns white : 1,7,9\n",
    "aisles[3] = [i for i in range(1, 8)] #Row 3, Columns white : 1-7,9\n",
    "aisles[3].append(9)\n",
    "aisles[4] = [3, 7] #Row 4, Columns white : 3,7\n",
    "aisles[5] = [i for i in range(11)] #Row 5, Columns white : 0-10\n",
    "aisles[6] = [5] #Row 6, Columns white : 5\n",
    "aisles[7] = [i for i in range(1, 10)] #Row 7, Columns white : 1-9\n",
    "aisles[8] = [3, 7] #Row 8, Columns white : 3,7\n",
    "aisles[9] = [i for i in range(11)] #Row 9, Columns white : 0-10\n",
    "\n",
    "#set the rewards for all aisle locations (i.e., white squares)\n",
    "for row_index in range(1, 10):\n",
    "    for column_index in aisles[row_index]:\n",
    "        rewards[row_index, column_index] = -1.\n",
    "\n",
    "#print rewards matrix\n",
    "for row in rewards:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GFEor01iCCin"
   },
   "source": [
    "## Train the Model\n",
    "Our next task is for our AI agent to learn about its environment by implementing a Q-learning model. The learning process will follow these steps:\n",
    "1. Choose a random, non-terminal state (white square) for the agent to begin this new episode.\n",
    "2. Choose an action (move *up*, *right*, *down*, or *left*) for the current state. Actions will be chosen using an *epsilon greedy algorithm*. This algorithm will usually choose the most promising action for the AI agent, but it will occasionally choose a less promising option in order to encourage the agent to explore the environment.\n",
    "3. Perform the chosen action, and transition to the next state (i.e., move to the next location).\n",
    "4. Receive the reward for moving to the new state, and calculate the temporal difference.\n",
    "5. Update the Q-value for the previous state and action pair.\n",
    "6. If the new (current) state is a terminal state, go to #1. Else, go to #2.\n",
    "\n",
    "This entire process will be repeated across 1000 episodes. This will provide the AI agent sufficient opportunity to learn the shortest paths between the item packaging area and all other locations in the warehouse where the robot is allowed to travel, while simultaneously avoiding crashing into any of the item storage locations!\n",
    "\n",
    "#### Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DnCfO5tVG0LJ"
   },
   "outputs": [],
   "source": [
    "#define a function that determines if the specified location is a terminal state\n",
    "def is_terminal_state(current_row_index, current_column_index):\n",
    "  #if the reward for this location is -1, then it is not a terminal state (i.e., it is a 'white square')\n",
    "  if rewards[current_row_index, current_column_index] == -1.:\n",
    "    return False\n",
    "  else:\n",
    "    return True\n",
    "\n",
    "#define a function that will choose a random, non-terminal starting location\n",
    "def get_starting_location():\n",
    "  #get a random row and column index\n",
    "    current_row_index = np.random.randint(environment_rows)\n",
    "    current_column_index = np.random.randint(environment_columns)\n",
    "  #continue choosing random row and column indexes until a non-terminal state is identified\n",
    "  #(i.e., until the chosen state is a 'white square').\n",
    "    while is_terminal_state(current_row_index, current_column_index):\n",
    "        current_row_index = np.random.randint(environment_rows)\n",
    "        current_column_index = np.random.randint(environment_columns)\n",
    "    return current_row_index, current_column_index\n",
    "\n",
    "#define an epsilon greedy algorithm that will choose which action to take next (i.e., where to move next)\n",
    "def get_next_action(current_row_index, current_column_index, epsilon):\n",
    "  #if a randomly chosen value between 0 and 1 is less than epsilon,\n",
    "  #then choose the most promising value from the Q-table for this state.\n",
    "    if np.random.random() < epsilon:\n",
    "        return np.argmax(q_values[current_row_index, current_column_index])\n",
    "    else: #choose a random action\n",
    "        return np.random.randint(4)\n",
    "\n",
    "#define a function that will get the next location based on the chosen action\n",
    "def get_next_location(current_row_index, current_column_index, action_index):\n",
    "    new_row_index = current_row_index\n",
    "    new_column_index = current_column_index\n",
    "    if actions[action_index] == 'up' and current_row_index > 0:\n",
    "        new_row_index -= 1\n",
    "    elif actions[action_index] == 'right' and current_column_index < environment_columns - 1:\n",
    "        new_column_index += 1\n",
    "    elif actions[action_index] == 'down' and current_row_index < environment_rows - 1:\n",
    "        new_row_index += 1\n",
    "    elif actions[action_index] == 'left' and current_column_index > 0:\n",
    "        new_column_index -= 1\n",
    "    return new_row_index, new_column_index\n",
    "\n",
    "#Define a function that will get the shortest path between any location within the warehouse that\n",
    "#the robot is allowed to travel and the item packaging location.\n",
    "def get_shortest_path(start_row_index, start_column_index):\n",
    "  #return immediately if this is an invalid starting location\n",
    "  if is_terminal_state(start_row_index, start_column_index):\n",
    "    return []\n",
    "  else: #if this is a 'legal' starting location\n",
    "    current_row_index, current_column_index = start_row_index, start_column_index\n",
    "    shortest_path = []\n",
    "    shortest_path.append([current_row_index, current_column_index])\n",
    "    #continue moving along the path until we reach the goal (i.e., the item packaging location)\n",
    "    while not is_terminal_state(current_row_index, current_column_index):\n",
    "      #get the best action to take\n",
    "      action_index = get_next_action(current_row_index, current_column_index, 1.)\n",
    "      #move to the next location on the path, and add the new location to the list\n",
    "      current_row_index, current_column_index = get_next_location(current_row_index, current_column_index, action_index)\n",
    "    shortest_path.append([current_row_index, current_column_index])\n",
    "    return shortest_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjl9niKEqONs"
   },
   "source": [
    "#### Train the AI Agent using Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3N5BB0m0JHIn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "#define training parameters\n",
    "epsilon = 0.9 #the percentage of time when we should take the best action (instead of a random action)\n",
    "discount_factor = 0.9 #discount factor for future rewards\n",
    "learning_rate = 0.9 #the rate at which the AI agent should learn\n",
    "\n",
    "#run through 1000 training episodes\n",
    "for episode in range(1000):\n",
    "  #get the starting location for this episode\n",
    "    row_index, column_index = get_starting_location()\n",
    "\n",
    "  #continue taking actions (i.e., moving) until we reach a terminal state\n",
    "  #(i.e., until we reach the item packaging area or crash into an item storage location)\n",
    "    while not is_terminal_state(row_index, column_index):\n",
    "    #choose which action to take (i.e., where to move next)\n",
    "        action_index = get_next_action(row_index, column_index, epsilon)\n",
    "\n",
    "    #perform the chosen action, and transition to the next state (i.e., move to the next location)\n",
    "        old_row_index, old_column_index = row_index, column_index #store the old row and column indexes\n",
    "        row_index, column_index = get_next_location(row_index, column_index, action_index)\n",
    "\n",
    "    #receive the reward for moving to the new state, and calculate the temporal difference\n",
    "        reward = rewards[row_index, column_index]\n",
    "        old_q_value = q_values[old_row_index, old_column_index, action_index]\n",
    "        temporal_difference = reward + (discount_factor * np.max(q_values[row_index, column_index])) - old_q_value\n",
    "\n",
    "    #update the Q-value for the previous state and action pair\n",
    "        new_q_value = old_q_value + (learning_rate * temporal_difference)\n",
    "        q_values[old_row_index, old_column_index, action_index] = new_q_value\n",
    "\n",
    "print('Training complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-100. -100. -100. -100. -100.  100. -100. -100. -100. -100. -100.]\n",
      " [-100.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1. -100.]\n",
      " [-100.   -1. -100. -100. -100. -100. -100.   -1. -100.   -1. -100.]\n",
      " [-100.   -1.   -1.   -1.   -1.   -1.   -1.   -1. -100.   -1. -100.]\n",
      " [-100. -100. -100.   -1. -100. -100. -100.   -1. -100. -100. -100.]\n",
      " [  -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.]\n",
      " [-100. -100. -100. -100. -100.   -1. -100. -100. -100. -100. -100.]\n",
      " [-100.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1. -100.]\n",
      " [-100. -100. -100.   -1. -100. -100. -100.   -1. -100. -100. -100.]\n",
      " [  -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.]\n",
      " [-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.]]\n"
     ]
    }
   ],
   "source": [
    "print(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]]\n",
      "\n",
      " [[   0.            0.            0.            0.        ]\n",
      "  [ -99.9          62.171        48.40744861  -99.        ]\n",
      "  [ -90.           70.19        -99.           54.89485959]\n",
      "  [ -90.           79.1         -90.           55.9539    ]\n",
      "  [ -99.9999       89.          -99.99         70.11981   ]\n",
      "  [ 100.           79.1        -100.           79.1       ]\n",
      "  [-100.           70.19       -100.           89.        ]\n",
      "  [ -99.9999       62.17099999   62.17099994   79.1       ]\n",
      "  [ -99.           54.89648091  -99.9          70.19      ]\n",
      "  [ -99.9         -99.           -3.18251215   62.171     ]\n",
      "  [   0.            0.            0.            0.        ]]\n",
      "\n",
      " [[   0.            0.            0.            0.        ]\n",
      "  [  54.9539      -99.           38.02036666  -99.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [  70.19       -100.           54.95389999  -99.99999   ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [  54.9539      -99.           37.83121713  -90.        ]\n",
      "  [   0.            0.            0.            0.        ]]\n",
      "\n",
      " [[   0.            0.            0.            0.        ]\n",
      "  [  48.45851      36.93241571  -99.          -90.        ]\n",
      "  [ -90.           -4.54663392  -90.           42.612659  ]\n",
      "  [ -99.999999     37.3513931    28.0220458    36.93152233]\n",
      "  [ -99.9          42.612659    -99.99         32.24348956]\n",
      "  [ -99.9          48.45851     -99.99999      36.94163919]\n",
      "  [ -99.999        54.9539      -99.99999      42.15167746]\n",
      "  [  62.171      -100.           48.45850995   48.45851   ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [  48.45850876  -99.          -90.          -99.        ]\n",
      "  [   0.            0.            0.            0.        ]]\n",
      "\n",
      " [[   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [  32.61625379  -99.9          24.48654637  -99.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [  54.9539     -100.           42.612659   -100.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]]\n",
      "\n",
      " [[ -90.           17.96052405  -99.9          -6.77524513]\n",
      "  [ -99.           21.06724901  -99.99         12.9545268 ]\n",
      "  [ -99.           24.51916557  -99.9          17.13396743]\n",
      "  [  28.35462841   24.98603538  -99.999        -5.31556769]\n",
      "  [ -90.           32.61625379  -99.           21.50433764]\n",
      "  [-100.           37.3513931    28.35462841   28.02658666]\n",
      "  [ -99.99999999   42.612659    -99.99999999   32.61625379]\n",
      "  [  48.45851      37.35139306  -99.99999      37.35098106]\n",
      "  [ -99.9          32.41765947  -99.999        42.612659  ]\n",
      "  [ -90.           -5.72071273  -90.           37.3513931 ]\n",
      "  [ -99.           -5.720702    -99.           32.61625379]]\n",
      "\n",
      " [[   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [  32.61625379 -100.           24.51916557  -99.99999   ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]]\n",
      "\n",
      " [[   0.            0.            0.            0.        ]\n",
      "  [ -90.           15.1644717   -90.          -90.        ]\n",
      "  [ -99.           17.96052411  -99.9999       12.61822302]\n",
      "  [ -99.99999      21.06724901   13.00035335   15.16227994]\n",
      "  [ -99.9999       24.51916557  -99.9          17.96052387]\n",
      "  [  28.35462841   21.06461824  -99.9999999    21.06724634]\n",
      "  [ -99.9999       15.5937352   -99.9          24.51916557]\n",
      "  [ -99.9999       15.16235433   14.94615575   21.06724901]\n",
      "  [ -99.999        -6.39735795  -90.           17.96052411]\n",
      "  [ -99.9         -90.          -90.           15.1644717 ]\n",
      "  [   0.            0.            0.            0.        ]]\n",
      "\n",
      " [[   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [  17.96052411  -99.9999       -6.81051985  -99.9999    ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [  17.96052411  -99.99         10.70768569  -99.9       ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]]\n",
      "\n",
      " [[ -99.            8.34489987  -99.           -7.56991824]\n",
      "  [ -99.999        10.38322208  -99.           -7.3295851 ]\n",
      "  [ -99.           12.64802453  -99.9999        8.18783732]\n",
      "  [  15.1644717    10.2091317   -99.999        10.21133456]\n",
      "  [ -99.99          6.38226793  -99.99         12.64802453]\n",
      "  [ -99.99         -7.30172271  -99.9          10.38322208]\n",
      "  [ -90.           12.64802453  -90.            6.77866133]\n",
      "  [  15.1644717     8.64329762  -99.99         10.04138585]\n",
      "  [ -99.            6.78922514  -99.           12.64802453]\n",
      "  [ -99.           -7.34957433  -99.9          10.38322208]\n",
      "  [ -90.            5.10235989  -99.9999        8.34489987]]\n",
      "\n",
      " [[   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]\n",
      "  [   0.            0.            0.            0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "print(q_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JqQfjYdfyBh"
   },
   "source": [
    "## Get Shortest Paths\n",
    "Now that the AI agent has been fully trained, we can see what it has learned by displaying the shortest path between any location in the warehouse where the robot is allowed to travel and the item packaging area.\n",
    "\n",
    "![warehouse map](https://www.danielsoper.com/teaching/img/08-warehouse-map.png)\n",
    "\n",
    "Run the code cell below to try a few different starting locations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "F1YO3mj_oS2J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 9], [0, 5]]\n",
      "[[5, 0], [0, 5]]\n",
      "[[9, 5], [0, 5]]\n"
     ]
    }
   ],
   "source": [
    "#display a few shortest paths\n",
    "print(get_shortest_path(3, 9)) #starting at row 3, column 9\n",
    "print(get_shortest_path(5, 0)) #starting at row 5, column 0\n",
    "print(get_shortest_path(9, 5)) #starting at row 9, column 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWx7BsJxqrDv"
   },
   "source": [
    "#### Finally...\n",
    "It's great that our robot can automatically take the shortest path from any 'legal' location in the warehouse to the item packaging area. **But what about the opposite scenario?**\n",
    "\n",
    "Put differently, our robot can currently deliver an item from anywhere in the warehouse ***to*** the packaging area, but after it delivers the item, it will need to travel ***from*** the packaging area to another location in the warehouse to pick up the next item!\n",
    "\n",
    "Don't worry -- this problem is easily solved simply by ***reversing the order of the shortest path***.\n",
    "\n",
    "Run the code cell below to see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "fKun8LInsas9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 5], [5, 2]]\n"
     ]
    }
   ],
   "source": [
    "#display an example of reversed shortest path\n",
    "path = get_shortest_path(5, 2) #go to row 5, column 2\n",
    "path.reverse()\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "(100,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "nSteps = 100 #number of time steps, in each time step, AP chooses a new channel\n",
    "\n",
    "#----Choose 1 channel out of (1,2,3,4) and take its corresponding channel power gain, g, in each time slot\n",
    "k = np.random.randint(low=1, high = 5, size=nSteps) #channel is decided randomly\n",
    "n = np.array([1.5,3,4.5,6])\n",
    "g = n[k-1]*1e-3\n",
    "\n",
    "\n",
    "K_J = np.random.randint(low=0, high = 2, size=nSteps) #should be an array randomly changing between 0 and 1 of dimension = number of time steps\n",
    "P_J = K_J #Absence of jammer in the channel indicates no jamming power\n",
    "\n",
    "r = 0.25\n",
    "τ = 1 #duration of each time slot is 1s\n",
    "τ_sense = 0.15\n",
    "τ_switch = np.array([0 if val == 1 else 0.1 for val in K_J])\n",
    "τ_EH = τ - (r*τ) - (τ_sense + τ_switch)\n",
    "\n",
    "P_T = 1# 1W of transmission power used by AP\n",
    "ξ = 0.8 #energy harvesting efficiency\n",
    "U_E = ξ*(abs(g)**2)*(P_J + P_T)*τ_EH #Unit Energy\n",
    "E_BC = 1*U_E # Let 1 unit of energy is used \n",
    "E_EH = 1*U_E\n",
    "E_h = k*U_E\n",
    "    \n",
    "#Reflection coeffcient\n",
    "s_bb = np.array([np.random.choice([1, -1]) for _ in range(nSteps)])\n",
    "mu = np.array([1 if val == 1 else 0 for val in s_bb]) # uniform random symbols from 0's and 1's, when tag wants to transmit 0, mu = 0, when tag wants to transmit 1, mu = 1\n",
    "\n",
    "E_B = np.zeros(nSteps)\n",
    "\n",
    "for j in range(nSteps):\n",
    "    E_B [j] = E_B [j] - mu[j]*E_BC[j] - (1 - mu[j])*E_EH[j] + (1 - mu[j])*E_h[j] + 1*U_E[j]\n",
    "\n",
    "print(len(E_B))\n",
    "print(np.shape(K_J))\n",
    "#define actions\n",
    "#numeric action codes: 0 = up, 1 = right, 2 = down, 3 = left\n",
    "actions = ['Channel 1', 'Channel 2', 'Channel 3', 'Channel 4']\n",
    "\n",
    "q_values = np.zeros((len(E_B), len(K_J), 4))\n",
    "q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_values = np.zeros((100, 100, 4))\n",
    "q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#k = np.random.randint(low=1, high = 5, size=5)\n",
    "for j in range (5+1):\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import randrange, uniform\n",
    "K = 4\n",
    "# randrange gives you an integral value\n",
    "d = randrange(1, K+1)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26344598948393505"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p0 = np.random.uniform(low=0.0, high=1.0, size=None)\n",
    "p0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 4 4] [0.0045 0.003  0.0015 0.0015]\n"
     ]
    }
   ],
   "source": [
    "k = np.random.randint(low=1, high = 5, size=4) #channel is decided randomly\n",
    "n = np.array([6,4.5,3,1.5])\n",
    "g = n[(k-1)]*1e-3\n",
    "print(k,g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "\n",
    "#1) States, S ∈ {EB , KJ , PT , k}, 0 ≤ k ≤ K − 1\n",
    "#2) Actions, A ∈ {ak}, 0 ≤ k ≤ K − 1\n",
    "\n",
    "\n",
    "#----Choose 1 channel between channel 1 (900MHz), 2(910MHz), 3(920MHz) or 4(930MHz)---\n",
    "deltaf = 10e6\n",
    "Fc = 900e6 #900MHz\n",
    "k = np.random.randint(low=1, high = 5) #channel is decided randomly\n",
    "d_k = k-1\n",
    "h_k = Fc + (d_k*deltaf)\n",
    "\n",
    "\n",
    "#define the shape of the environment (i.e., its states)\n",
    "\n",
    "#environment_rows = 11\n",
    "#environment_columns = 11\n",
    "\n",
    "nSteps = 100 #number of time steps, in each time step, AP chooses a new channel\n",
    "#----Choose 1 channel out of (1,2,3,4) and take its corresponding channel power gain, g, in each time slot\n",
    "k = np.random.randint(low=1, high = 5, size=nSteps) #channel is decided randomly\n",
    "n = np.array([6,4.5,3,1.5])\n",
    "g = n[(k-1)]*1e-3 #channel power gain linearly related i.e. high frequency, low channel gain\n",
    "#Jammer\n",
    "K_J = np.random.randint(low=0, high = 2, size=nSteps) #should be an array randomly changing between 0 and 1 of dimension = number of time steps\n",
    "P_J = K_J #Absence of jammer in the channel indicates no jamming power; jamming power = 1W\n",
    "\n",
    "#Distribute the time slot in CS+EH+BC\n",
    "r = 0.25\n",
    "τ = 1 #duration of each time slot is 1s\n",
    "τ_sense = 0.15\n",
    "τ_switch = np.array([0 if val == 1 else 0.1 for val in K_J])\n",
    "τ_EH = τ - (r*τ) - (τ_sense + τ_switch)\n",
    "#Let's assign the power and energy levels\n",
    "P_T = 1# 1W of transmission power used by AP\n",
    "ξ = 0.8 #energy harvesting efficiency\n",
    "U_E = ξ*(abs(g)**2)*(P_J + P_T)*τ_EH #Unit Energy\n",
    "E_BC = 1*U_E # Let 1 Unit energy used, fixed, by tag circuit during BC operation\n",
    "E_EH = 1*U_E # Let 1 Unit energy used, fixed, by tag circuit during EH operation \n",
    "E_h = k*U_E # Let amount of harvested energy depends on which channel it is using e.g. for channel 1, E_h = 1*U_E, for channel 2, 2*U_E and so on\n",
    "\n",
    "    \n",
    "#Reflection coeffcient\n",
    "s_bb = np.array([np.random.choice([1, -1]) for _ in range(nSteps)])\n",
    "mu = np.array([1 if val == 1 else 0 for val in s_bb]) # uniform random symbols from 0's and 1's, when tag wants to transmit 0, mu = 0, when tag wants to transmit 1, mu = 1\n",
    "\n",
    "E_B = np.zeros(nSteps)\n",
    "\n",
    "for j in range(nSteps):\n",
    "    E_B [j] = E_B [j] - mu[j]*E_BC[j] - (1 - mu[j])*E_EH[j] + (1 - mu[j])*E_h[j] + 1*U_E[j]\n",
    "\n",
    "state = np.array([K_J, E_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 100)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.000e+00 0.000e+00 1.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 1.000e+00 0.000e+00 1.000e+00 1.000e+00 0.000e+00 1.000e+00\n",
      "  0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      "  1.000e+00 1.000e+00 1.000e+00 0.000e+00 1.000e+00 1.000e+00 1.000e+00\n",
      "  1.000e+00 0.000e+00 1.000e+00 0.000e+00 1.000e+00 1.000e+00 1.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 1.000e+00 1.000e+00 1.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      "  0.000e+00 1.000e+00 0.000e+00 1.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 1.000e+00 1.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      "  0.000e+00 1.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  1.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 1.000e+00\n",
      "  0.000e+00 1.000e+00 0.000e+00 1.000e+00 1.000e+00 0.000e+00 1.000e+00\n",
      "  0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00\n",
      "  0.000e+00 1.000e+00]\n",
      " [1.440e-05 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  1.080e-05 0.000e+00 0.000e+00 3.456e-05 0.000e+00 0.000e+00 2.592e-05\n",
      "  3.600e-06 0.000e+00 0.000e+00 0.000e+00 1.620e-05 8.640e-06 0.000e+00\n",
      "  3.456e-05 0.000e+00 2.592e-05 0.000e+00 8.640e-06 0.000e+00 0.000e+00\n",
      "  3.888e-05 1.440e-05 3.456e-05 0.000e+00 0.000e+00 0.000e+00 8.640e-06\n",
      "  1.620e-05 1.620e-05 1.080e-05 0.000e+00 3.456e-05 0.000e+00 1.440e-05\n",
      "  0.000e+00 8.640e-06 0.000e+00 8.640e-06 1.440e-05 3.456e-05 0.000e+00\n",
      "  1.080e-05 0.000e+00 3.600e-06 1.080e-05 0.000e+00 3.456e-05 0.000e+00\n",
      "  0.000e+00 3.456e-05 0.000e+00 3.888e-05 0.000e+00 0.000e+00 1.440e-05\n",
      "  1.620e-05 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 8.640e-06 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.080e-05\n",
      "  0.000e+00 0.000e+00 1.440e-05 0.000e+00 0.000e+00 0.000e+00 3.456e-05\n",
      "  1.080e-05 0.000e+00 1.620e-05 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  1.620e-05 2.592e-05 0.000e+00 3.600e-06 0.000e+00 0.000e+00 3.888e-05\n",
      "  0.000e+00 3.456e-05]]\n"
     ]
    }
   ],
   "source": [
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00e+00, 1.44e-05])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U = state[:,0]\n",
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 82\n"
     ]
    }
   ],
   "source": [
    "next_row = np.random.randint(low=0, high = 2)\n",
    "next_column = np.random.randint(low=0, high = 100)\n",
    "print(next_row,next_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.66838362 0.4103579  0.0697746  0.8303517 ]\n",
      "  [0.82618682 0.03318573 0.41352775 0.94849656]\n",
      "  [0.33486524 0.81327705 0.05308843 0.50264276]]\n",
      "\n",
      " [[0.38816431 0.28243416 0.47492171 0.19773776]\n",
      "  [0.12573328 0.8924733  0.74196385 0.81674982]\n",
      "  [0.93322222 0.94570638 0.34829318 0.37028252]]]\n",
      "2\n",
      "(2, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "#state = np.random.rand(2,100)\n",
    "#row = state[]\n",
    "q_table = np.random.rand(2,3,4)\n",
    "print(q_table)\n",
    "print(len(q_table))\n",
    "print(np.shape(q_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "K_J = np.random.randint(low=0, high = 2, size=100)\n",
    "print(np.shape(K_J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.80284578 0.01194902 0.41168095 0.77392066]\n",
      "  [0.35261173 0.32562449 0.32706888 0.37267393]\n",
      "  [0.35159665 0.52696494 0.29479223 0.60142558]\n",
      "  [0.59724564 0.97160071 0.80860265 0.55949034]\n",
      "  [0.59541497 0.25614193 0.84686993 0.81805394]\n",
      "  [0.09796632 0.96895653 0.70309402 0.92365937]\n",
      "  [0.22172416 0.04592308 0.89239432 0.00468517]\n",
      "  [0.6849288  0.84987956 0.10078164 0.9189663 ]\n",
      "  [0.01656204 0.97221451 0.81537811 0.57553775]\n",
      "  [0.17661353 0.30923953 0.72724295 0.52114328]]\n",
      "\n",
      " [[0.47290783 0.52935424 0.36929071 0.57823092]\n",
      "  [0.81729501 0.67748468 0.40330701 0.42186247]\n",
      "  [0.35302392 0.20885734 0.35842378 0.36444559]\n",
      "  [0.52785784 0.54789743 0.23047945 0.47036797]\n",
      "  [0.74751165 0.4682059  0.15323457 0.73722226]\n",
      "  [0.60677931 0.91019542 0.10246589 0.5237903 ]\n",
      "  [0.54136046 0.63696998 0.36766315 0.74720264]\n",
      "  [0.97287841 0.96493776 0.05640609 0.12169269]\n",
      "  [0.8397849  0.16565435 0.20712717 0.76556553]\n",
      "  [0.49799653 0.28095309 0.68869288 0.62946539]]\n",
      "\n",
      " [[0.57433165 0.96943392 0.66271522 0.29003395]\n",
      "  [0.30552319 0.36415644 0.84346517 0.06119713]\n",
      "  [0.81042551 0.41628521 0.50478157 0.03671216]\n",
      "  [0.66263392 0.53723546 0.19208593 0.5689257 ]\n",
      "  [0.62073044 0.79092013 0.90628549 0.5316082 ]\n",
      "  [0.66172173 0.68581353 0.72107581 0.49384085]\n",
      "  [0.68762155 0.65650904 0.80053133 0.38851054]\n",
      "  [0.15258141 0.98116943 0.1311431  0.54055   ]\n",
      "  [0.26022611 0.19374266 0.95683694 0.03621271]\n",
      "  [0.54746101 0.48762013 0.63923358 0.39585315]]\n",
      "\n",
      " [[0.44662981 0.04039907 0.89064969 0.7228104 ]\n",
      "  [0.35401005 0.87801751 0.07610656 0.09491596]\n",
      "  [0.99246573 0.44189625 0.37502623 0.80571384]\n",
      "  [0.59256808 0.84659843 0.25355057 0.87833309]\n",
      "  [0.36024971 0.32956155 0.96486005 0.96940987]\n",
      "  [0.97863738 0.32004228 0.73778691 0.62150586]\n",
      "  [0.48163188 0.82634884 0.05648763 0.49700207]\n",
      "  [0.21891891 0.42117583 0.85225061 0.01353406]\n",
      "  [0.48734993 0.71140293 0.33073973 0.00818321]\n",
      "  [0.4498301  0.02739196 0.23687535 0.58550221]]\n",
      "\n",
      " [[0.92039659 0.58105953 0.00546739 0.76127876]\n",
      "  [0.10756514 0.99025309 0.90589484 0.81939633]\n",
      "  [0.96569394 0.77301237 0.32080201 0.75958444]\n",
      "  [0.75852804 0.13284263 0.96749557 0.83775471]\n",
      "  [0.44825088 0.81108515 0.94486356 0.11422172]\n",
      "  [0.43629075 0.18157037 0.39018467 0.89650394]\n",
      "  [0.88661661 0.36829071 0.86172365 0.76730657]\n",
      "  [0.25937305 0.17850641 0.22441124 0.02273664]\n",
      "  [0.06920888 0.30015682 0.44212885 0.98923433]\n",
      "  [0.1265623  0.48372961 0.2978673  0.79826516]]\n",
      "\n",
      " [[0.84833064 0.15811593 0.40707907 0.21428441]\n",
      "  [0.09911561 0.9474872  0.36216791 0.147928  ]\n",
      "  [0.61463601 0.59872078 0.7383612  0.99143443]\n",
      "  [0.02177524 0.52514411 0.03850756 0.40223139]\n",
      "  [0.15492029 0.71104886 0.72540208 0.99302872]\n",
      "  [0.63131622 0.58858116 0.58577387 0.75057654]\n",
      "  [0.61609863 0.17740063 0.14936141 0.24301876]\n",
      "  [0.91706292 0.08752113 0.06503913 0.28847839]\n",
      "  [0.62895291 0.27249654 0.47339137 0.5550646 ]\n",
      "  [0.26582121 0.65079396 0.55421444 0.71715339]]\n",
      "\n",
      " [[0.58095035 0.25413304 0.45635136 0.48490678]\n",
      "  [0.16981702 0.16053933 0.04098504 0.69448684]\n",
      "  [0.60783916 0.18851753 0.89734638 0.25532549]\n",
      "  [0.30261741 0.65374405 0.96438665 0.57501511]\n",
      "  [0.54039543 0.03804689 0.0936325  0.90651937]\n",
      "  [0.56687747 0.96858515 0.49937041 0.01991918]\n",
      "  [0.17311589 0.02545355 0.24347366 0.26783244]\n",
      "  [0.26002986 0.2504629  0.2694586  0.11572714]\n",
      "  [0.62413938 0.2587474  0.22428679 0.06829558]\n",
      "  [0.38918079 0.9591175  0.78108054 0.71833469]]\n",
      "\n",
      " [[0.2757168  0.04688329 0.85134204 0.03275219]\n",
      "  [0.98734685 0.84243632 0.21224071 0.93938206]\n",
      "  [0.38833174 0.73215744 0.31985171 0.40929985]\n",
      "  [0.6471839  0.60894962 0.77921917 0.19790363]\n",
      "  [0.61540578 0.50830269 0.44145631 0.35407957]\n",
      "  [0.81133519 0.35052799 0.38201252 0.74065319]\n",
      "  [0.83118229 0.61212475 0.13875655 0.01967382]\n",
      "  [0.2976843  0.45856433 0.33861429 0.59454668]\n",
      "  [0.05659229 0.77637352 0.65223821 0.49769056]\n",
      "  [0.48355465 0.11463953 0.19616827 0.43871047]]\n",
      "\n",
      " [[0.54473063 0.83550923 0.8095588  0.98051885]\n",
      "  [0.39783962 0.64459195 0.33306955 0.13645857]\n",
      "  [0.63542746 0.21530739 0.19568625 0.93198559]\n",
      "  [0.20712192 0.39848602 0.11366705 0.0676828 ]\n",
      "  [0.10370643 0.0665061  0.2581029  0.23876326]\n",
      "  [0.16039693 0.04163341 0.72929134 0.17761982]\n",
      "  [0.31105857 0.77936041 0.17653227 0.17014852]\n",
      "  [0.53699736 0.41905264 0.08098702 0.74406074]\n",
      "  [0.93567506 0.25350034 0.02959457 0.17281343]\n",
      "  [0.87181821 0.5670563  0.66275119 0.06603533]]\n",
      "\n",
      " [[0.30913656 0.73557396 0.0546588  0.71275434]\n",
      "  [0.26908714 0.69077409 0.17035679 0.07385003]\n",
      "  [0.78764501 0.95057421 0.32364595 0.05972118]\n",
      "  [0.79191232 0.11293118 0.90365595 0.05121681]\n",
      "  [0.34350669 0.83531888 0.35943837 0.54971495]\n",
      "  [0.52858787 0.10326863 0.01586195 0.44378226]\n",
      "  [0.17656028 0.393226   0.14909389 0.59960618]\n",
      "  [0.31463947 0.68025156 0.68590254 0.74150926]\n",
      "  [0.31754541 0.13867984 0.17830845 0.04170776]\n",
      "  [0.72289188 0.21871037 0.94995266 0.36262714]]]\n"
     ]
    }
   ],
   "source": [
    "# Assume Q_table is the learned Q-table (a 2D array where rows represent states and columns represent actions)\n",
    "# state is the current state for which you want to find the optimal action\n",
    "E_B = np.random.rand(10)\n",
    "K_J = np.random.randint(low=0, high = 2, size=10)\n",
    "q_table = np.random.rand((len(E_B)),(len(E_B)),4)\n",
    "print(q_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal action for state 0 0 is action 0\n",
      "Optimal action for state 0 1 is action 3\n",
      "Optimal action for state 0 2 is action 3\n",
      "Optimal action for state 0 3 is action 1\n",
      "Optimal action for state 0 4 is action 2\n",
      "Optimal action for state 0 5 is action 1\n",
      "Optimal action for state 0 6 is action 2\n",
      "Optimal action for state 0 7 is action 3\n",
      "Optimal action for state 0 8 is action 1\n",
      "Optimal action for state 0 9 is action 2\n",
      "Optimal action for state 1 0 is action 3\n",
      "Optimal action for state 1 1 is action 0\n",
      "Optimal action for state 1 2 is action 3\n",
      "Optimal action for state 1 3 is action 1\n",
      "Optimal action for state 1 4 is action 0\n",
      "Optimal action for state 1 5 is action 1\n",
      "Optimal action for state 1 6 is action 3\n",
      "Optimal action for state 1 7 is action 0\n",
      "Optimal action for state 1 8 is action 0\n",
      "Optimal action for state 1 9 is action 2\n",
      "Optimal action for state 2 0 is action 1\n",
      "Optimal action for state 2 1 is action 2\n",
      "Optimal action for state 2 2 is action 0\n",
      "Optimal action for state 2 3 is action 0\n",
      "Optimal action for state 2 4 is action 2\n",
      "Optimal action for state 2 5 is action 2\n",
      "Optimal action for state 2 6 is action 2\n",
      "Optimal action for state 2 7 is action 1\n",
      "Optimal action for state 2 8 is action 2\n",
      "Optimal action for state 2 9 is action 2\n",
      "Optimal action for state 3 0 is action 2\n",
      "Optimal action for state 3 1 is action 1\n",
      "Optimal action for state 3 2 is action 0\n",
      "Optimal action for state 3 3 is action 3\n",
      "Optimal action for state 3 4 is action 3\n",
      "Optimal action for state 3 5 is action 0\n",
      "Optimal action for state 3 6 is action 1\n",
      "Optimal action for state 3 7 is action 2\n",
      "Optimal action for state 3 8 is action 1\n",
      "Optimal action for state 3 9 is action 3\n",
      "Optimal action for state 4 0 is action 0\n",
      "Optimal action for state 4 1 is action 1\n",
      "Optimal action for state 4 2 is action 0\n",
      "Optimal action for state 4 3 is action 2\n",
      "Optimal action for state 4 4 is action 2\n",
      "Optimal action for state 4 5 is action 3\n",
      "Optimal action for state 4 6 is action 0\n",
      "Optimal action for state 4 7 is action 0\n",
      "Optimal action for state 4 8 is action 3\n",
      "Optimal action for state 4 9 is action 3\n",
      "Optimal action for state 5 0 is action 0\n",
      "Optimal action for state 5 1 is action 1\n",
      "Optimal action for state 5 2 is action 3\n",
      "Optimal action for state 5 3 is action 1\n",
      "Optimal action for state 5 4 is action 3\n",
      "Optimal action for state 5 5 is action 3\n",
      "Optimal action for state 5 6 is action 0\n",
      "Optimal action for state 5 7 is action 0\n",
      "Optimal action for state 5 8 is action 0\n",
      "Optimal action for state 5 9 is action 3\n",
      "Optimal action for state 6 0 is action 0\n",
      "Optimal action for state 6 1 is action 3\n",
      "Optimal action for state 6 2 is action 2\n",
      "Optimal action for state 6 3 is action 2\n",
      "Optimal action for state 6 4 is action 3\n",
      "Optimal action for state 6 5 is action 1\n",
      "Optimal action for state 6 6 is action 3\n",
      "Optimal action for state 6 7 is action 2\n",
      "Optimal action for state 6 8 is action 0\n",
      "Optimal action for state 6 9 is action 1\n",
      "Optimal action for state 7 0 is action 2\n",
      "Optimal action for state 7 1 is action 0\n",
      "Optimal action for state 7 2 is action 1\n",
      "Optimal action for state 7 3 is action 2\n",
      "Optimal action for state 7 4 is action 0\n",
      "Optimal action for state 7 5 is action 0\n",
      "Optimal action for state 7 6 is action 0\n",
      "Optimal action for state 7 7 is action 3\n",
      "Optimal action for state 7 8 is action 1\n",
      "Optimal action for state 7 9 is action 0\n",
      "Optimal action for state 8 0 is action 3\n",
      "Optimal action for state 8 1 is action 1\n",
      "Optimal action for state 8 2 is action 3\n",
      "Optimal action for state 8 3 is action 1\n",
      "Optimal action for state 8 4 is action 2\n",
      "Optimal action for state 8 5 is action 2\n",
      "Optimal action for state 8 6 is action 1\n",
      "Optimal action for state 8 7 is action 3\n",
      "Optimal action for state 8 8 is action 0\n",
      "Optimal action for state 8 9 is action 0\n",
      "Optimal action for state 9 0 is action 1\n",
      "Optimal action for state 9 1 is action 1\n",
      "Optimal action for state 9 2 is action 1\n",
      "Optimal action for state 9 3 is action 2\n",
      "Optimal action for state 9 4 is action 1\n",
      "Optimal action for state 9 5 is action 0\n",
      "Optimal action for state 9 6 is action 3\n",
      "Optimal action for state 9 7 is action 3\n",
      "Optimal action for state 9 8 is action 0\n",
      "Optimal action for state 9 9 is action 2\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(E_B)):\n",
    "    for j in range(len(K_J)):\n",
    "        optimal_action = np.argmax(q_table[i,j,:]) #np.argmax(q_values_for_state)  \n",
    "        print(\"Optimal action for state\", i,j , \"is action\", optimal_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "array() takes from 1 to 2 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [145]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(a)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39margmax(a))\n",
      "\u001b[1;31mTypeError\u001b[0m: array() takes from 1 to 2 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "a = np.array([1,8,6],[2,9,4],[1,8,6],[2,9,4])\n",
    "print(a)\n",
    "print(np.argmax(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [110]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m state \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Get the row corresponding to the current state from the Q-table\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     q_values_for_state \u001b[38;5;241m=\u001b[39m q_table[state, :]\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Find the index of the action with the highest Q-value (optimal action)\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "for state in range(state):\n",
    "    # Get the row corresponding to the current state from the Q-table\n",
    "    q_values_for_state = q_table[state, :]\n",
    "    # Find the index of the action with the highest Q-value (optimal action)\n",
    "    optimal_action = np.argmax(q_values_for_state)\n",
    "    print(\"Optimal action for state\", state, \"is action\", optimal_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP uses channel 1 having frequency 900000000.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Execute in Python3: exec(open(\"chapter_2/bpsk.py\").read())\n",
    "import numpy as np #for numerical computing\n",
    "import matplotlib.pyplot as plt #for plotting functions\n",
    "#from DigiCommPy.passband_modulations import bpsk_mod, bpsk_demod\n",
    "#from DigiCommPy.channels import awgn\n",
    "from scipy.special import erfc\n",
    "\n",
    "\n",
    "def bpsk_mod(ak,L):\n",
    "    from scipy.signal import upfirdn\n",
    "    s_bb = upfirdn(h=[1]*L, x=2*ak-1, up = L) # NRZ encoder\n",
    "    t=np.arange(start = 0,stop = len(ak)*L) #discrete time base\n",
    "    return (s_bb,t)\n",
    "\n",
    "\n",
    "N=5 # Number of symbols to transmit\n",
    "EbN0dB = np.arange(start=-4,stop = 11,step = 2) # Eb/N0 range in dB for simulation\n",
    "L=16 # oversampling factor,L=Tb/Ts(Tb=bit period,Ts=sampling period)\n",
    "# if a carrier is used, use L = Fs/Fc, where Fs >> 2xFc\n",
    "#Fc=900e-6 # carrier frequency\n",
    "\n",
    "#----Choose 1 channel between channel 1 (900MHz), 2(910MHz), 3(920MHz) or 4(930MHz)---\n",
    "deltaf = 10e6\n",
    "Fc = 900e6 #900MHz\n",
    "k = np.random.randint(low=1, high = 5) #channel is decided randomly\n",
    "d_k = k-1\n",
    "h_k = Fc + (d_k*deltaf)\n",
    "print('AP uses channel '+str(k)+' having frequency '+str(h_k))\n",
    "\n",
    "Fs=L*Fc # sampling frequency\n",
    "BER = np.zeros(len(EbN0dB)) # for BER values for each Eb/N0\n",
    "ak = np.random.randint(2, size=N) # uniform random symbols from 0's and 1's\n",
    "(s_bb,t)= bpsk_mod(ak,L) # BPSK modulation(waveform) - baseband\n",
    "\n",
    "\n",
    "\n",
    "# Waveforms at the transmitter\n",
    "#plotting the baseband signal\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(t,s_bb) # baseband wfm zoomed to first 10 bits\n",
    "plt.xlabel('time (in s)')\n",
    "plt.xlim(0,10*L);\n",
    "plt.ylabel(r'$s_{bb}(t)$-baseband')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(ak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.0, 2.0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "t = np.linspace(0, 1, 500, endpoint=False) #A 5 Hz waveform sampled at 500 Hz for 1s\n",
    "plt.plot(t, signal.square(-1*(2 * np.pi * 1 * t), duty=0.25)) #A 5 Hz waveform for 1s creating 5 cycles in 1s\n",
    "plt.ylim(-2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.,  1., -1., -1.,\n",
       "        1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,\n",
       "       -1., -1., -1., -1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,\n",
       "       -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1.,\n",
       "       -1., -1., -1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1.,\n",
       "       -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,\n",
       "       -1., -1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,\n",
       "        1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1., -1.,\n",
       "       -1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,\n",
       "       -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1., -1., -1.,\n",
       "       -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1.,\n",
       "       -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1.,\n",
       "       -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,\n",
       "        1., -1., -1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.,\n",
       "        1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,\n",
       "       -1., -1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.,  1.,\n",
       "       -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1.,\n",
       "       -1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.,  1., -1.,\n",
       "       -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,\n",
       "        1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.,\n",
       "        1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.,  1.,\n",
       "       -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1.,\n",
       "       -1.,  1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.,  1., -1.,\n",
       "       -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,\n",
       "        1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.,  1., -1., -1.,\n",
       "        1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,\n",
       "       -1., -1., -1., -1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,\n",
       "       -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1.,\n",
       "       -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,\n",
       "       -1., -1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,\n",
       "        1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1., -1.,\n",
       "       -1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,\n",
       "       -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1., -1., -1.,\n",
       "       -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1.,\n",
       "       -1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,\n",
       "        1., -1., -1.,  1., -1., -1.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=signal.square((2 * np.pi * 1 * t), duty=0.25)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.  -2.5 -2.  -1.5 -1.  -0.5  0.   0.5  1.   1.5  2.   2.5]\n"
     ]
    }
   ],
   "source": [
    "print(np.arange(-3, 3, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([3465.64546235, 3907.37043247, 4785.49809605, 6155.56881391,\n",
      "       7766.52307218, 9158.32621282, 9837.30500871, 9987.96644942])]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "#rewards\n",
    "R_b = 10e3 #10kbps - tag transmits with a fixed data rate R_b\n",
    "τ = 1\n",
    "C = np.zeros(8)\n",
    "rewards = np.zeros(8)\n",
    "rewards_all_episodes = []\n",
    "BER = np.array([3.6003e-01, 2.9812e-01, 2.1573e-01, 1.2898e-01, 5.8690e-02, 1.6520e-02, 2.3000e-03, 1.2000e-04])\n",
    "for j in range(len(BER)):\n",
    "    C[j] = 1 + BER[j]*math.log(BER[j]) + (1 - BER[j])*math.log(1 - BER[j])\n",
    "    rewards[j] = R_b*C[j]*τ\n",
    "rewards_all_episodes.append(rewards)\n",
    "print(rewards_all_episodes)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
